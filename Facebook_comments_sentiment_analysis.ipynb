{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Facebook_comments_sentiment_analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfBEr9IcBy3p",
        "outputId": "72429153-b647-49fb-f7c5-3a6643c8bcc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "fname = 'facebook_comments.csv'\n",
        "df_train = pd.read_csv(fname, header= None, names=['text','sentiment'],encoding='iso-8859-1',lineterminator='\\n')\n",
        "df_train.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Heres a single  to add  to Kindle. Just read t...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If you tire of Non-Fiction.. Check out http://...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ghost of Round Island is supposedly nonfiction.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why is Barnes and Nobles version of the Kindle...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@Maria:  Do you mean the Nook?  Be careful  bo...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment\n",
              "0  Heres a single  to add  to Kindle. Just read t...    neutral\n",
              "1  If you tire of Non-Fiction.. Check out http://...    neutral\n",
              "2   Ghost of Round Island is supposedly nonfiction.     neutral\n",
              "3  Why is Barnes and Nobles version of the Kindle...   negative\n",
              "4  @Maria:  Do you mean the Nook?  Be careful  bo...   positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0VvoOreDA8p"
      },
      "source": [
        "sent = {'positive':2, 'neutral':1,'negative':0}\n",
        "df_train['labels'] = df_train['sentiment'].str.strip().map(sent)  #mapping the sentiments of comments to numerical values"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acaLxhmXETax"
      },
      "source": [
        "training_texts = df_train.text.values  #creating numpy array for the training data\n",
        "labels = df_train.labels.values   #creating numpy array for the training labels"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJJM72FrFQp6",
        "outputId": "a328a11e-8201-4d8d-d86b-93da8a04b9a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Heres a single  to add  to Kindle. Just read t...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If you tire of Non-Fiction.. Check out http://...</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ghost of Round Island is supposedly nonfiction.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why is Barnes and Nobles version of the Kindle...</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@Maria:  Do you mean the Nook?  Be careful  bo...</td>\n",
              "      <td>positive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  sentiment  labels\n",
              "0  Heres a single  to add  to Kindle. Just read t...    neutral       1\n",
              "1  If you tire of Non-Fiction.. Check out http://...    neutral       1\n",
              "2   Ghost of Round Island is supposedly nonfiction.     neutral       1\n",
              "3  Why is Barnes and Nobles version of the Kindle...   negative       0\n",
              "4  @Maria:  Do you mean the Nook?  Be careful  bo...   positive       2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moAhHFf-FS5C",
        "outputId": "6960a326-d927-4a17-fb94-fa2bd7f6bd6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Preprocess Data \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words ='english', max_features=500, ngram_range= (1,2))  #creating the Tfidf object                           #use 1000 or 2000 here\n",
        "instances = vectorizer.fit_transform(training_texts)    #using raw data to create the Tfidf object which will return a matrix\n",
        "\n",
        "X = instances.toarray()  #after Tfidf what we get is a sparse marix, so converting it to an array here\n",
        "Y = np.array(labels)\n",
        "\n",
        "print(X.shape, ',', Y.shape) #X is a matrix, Y is a vector"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1999, 500) , (1999,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4mcDKdKGOey",
        "outputId": "8663a008-6b2a-47e6-f312-99164ef6c11d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Traditional Machine Learning: Random Forest\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "kfold = KFold(n_splits= 10, shuffle= True, random_state= 2020)\n",
        "rf_model = RandomForestClassifier(random_state= 2020, max_depth=2, criterion='entropy')\n",
        "rf_cvscores = []\n",
        "\n",
        "for train,test in kfold.split(X):\n",
        "  rf_model.fit(X[train], Y[train])\n",
        "  rf_acc = rf_model.score(X[test], Y[test])\n",
        "  rf_cvscores.append(rf_acc)\n",
        "\n",
        "print(\"RF - mean: %.4f%% (std: +/- %.4f%%)\" % (np.mean(rf_cvscores)*100, np.std(rf_cvscores)*100)  )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RF - mean: 64.1332% (std: +/- 2.0919%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbWD6CvuK-2V"
      },
      "source": [
        "#Fully Connected Feedforward Network\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import torch.optim as optim"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3iVVDTeIUgi"
      },
      "source": [
        "#Hyper parameter\n",
        "\n",
        "epochs = 15  #the model learns better with every epoch\n",
        "lr = 1e-3  #with a smaller learning rate the weight adjustments after backpropogation do not overshoot and learning is slow\n",
        "indim = X.shape[1]\n",
        "outdim = 3\n",
        "drate = 0.6   #the model does not show overfitting traits and is not complex so the dropout rate is small\n",
        "batch_size = 16   #based on the instances in the training dataset, a batch size of 16 provides enough batches to perform the parameter updation tasks\n",
        "\n",
        "X_tensor = torch.from_numpy(X)  #convert the X numpy array to tensors\n",
        "Y_tensor = torch.from_numpy(Y)  #convert the Y numpy array to tensors\n",
        "\n",
        "dataset = TensorDataset(X_tensor, Y_tensor)   #vertically concatanate the tensors to form the dataset with text values and labels\n",
        "train_size = int(0.8*len(dataset))         \n",
        "val_size = len(dataset) - train_size        \n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset,[train_size, val_size])  #random split of dataset into training and validation \n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle= True)  #training loader created by allowing shuffle of instances in epochs\n",
        "val_loader = DataLoader(val_dataset, batch_size= batch_size, shuffle= True)     \n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kudIudIvNGAT",
        "outputId": "a11fe1c7-6ba7-4507-bee0-e28ee2e18a26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "#Creating the network\n",
        "\n",
        "class SentimentNetwork(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim, dropout_rate):\n",
        "\n",
        "    super(SentimentNetwork, self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(input_dim,100)\n",
        "    self.do1 = nn.Dropout(dropout_rate)\n",
        "    self.fc2 = nn.Linear(100, 50)\n",
        "    self.fc3 = nn.Linear(50, output_dim)\n",
        "    \n",
        "# one dropout layer to avoid overfitting situations\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.do1(x)\n",
        "    x = F.relu(self.fc2(x))\n",
        "    return F.log_softmax(self.fc3(x))\n",
        "\n",
        "#creating model\n",
        "model = SentimentNetwork(indim, outdim, drate)\n",
        "print(model)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentNetwork(\n",
            "  (fc1): Linear(in_features=500, out_features=100, bias=True)\n",
            "  (do1): Dropout(p=0.6, inplace=False)\n",
            "  (fc2): Linear(in_features=100, out_features=50, bias=True)\n",
            "  (fc3): Linear(in_features=50, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgQtW-umJ4Gy"
      },
      "source": [
        "# define a training process function\n",
        "# Define the Loss function and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = lr)  #suitable with a small learning rate\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc6GYDoBN9qi"
      },
      "source": [
        "#define a training process function for one epoch\n",
        "def train(model, train_loader, optimizer, criterion):\n",
        "  epoch_loss, epoch_acc = 0.0, 0.0\n",
        "\n",
        "  model.train()  #for dropout, system needs to be told that this is the training mode\n",
        "  acc = 0\n",
        "  for batch_x, batch_y in train_loader:\n",
        "    \n",
        "    optimizer.zero_grad()  #settings gradient for all weights and biases to zero \n",
        "    net_out = model(batch_x.float())  \n",
        "    \n",
        "    error = criterion(net_out, batch_y)  #tensor returned\n",
        "    loss = error.item() #calculate the loss using predicted output and truth and only get values here\n",
        "\n",
        "    #acc = calculate the accuracy using predictions (batch_size x 3) and batch_y (batch_size x 1)\n",
        "    pred = net_out.argmax(1)      \n",
        "    acc = pred.eq(batch_y).sum().item()  #to get the number of correct predictions in a batch\n",
        "                                                          \n",
        "    #backpropogate\n",
        "    error.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    epoch_loss += loss   \n",
        "    epoch_acc += acc      #total number of correct predictions in an epoch\n",
        "\n",
        "  #avg epoch_loss and avg epoch_acc\n",
        "  avg_epoch_loss = epoch_loss/len(train_dataset)   #\n",
        "  avg_epoch_acc = epoch_acc/len(train_dataset)\n",
        "  return avg_epoch_loss, avg_epoch_acc\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4Ct00m6IjcL"
      },
      "source": [
        "#define a validation process function for one epoch\n",
        "def evaluate(model, val_loader, criterion):\n",
        "  epoch_loss, epoch_acc = 0.0, 0.0\n",
        "\n",
        "  acc = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch_x, batch_y in val_loader:\n",
        "      \n",
        "      net_out = model(batch_x.float())\n",
        "      error = criterion(net_out, batch_y)\n",
        "      loss = error.item()\n",
        "\n",
        "      #acc = calculate the accuracy using predictions (batch_size x 3) and batch_y (batch_size x 1)\n",
        "      pred = net_out.data.argmax(1) #(batch_size x 1)\n",
        "      acc = pred.eq(batch_y).sum().item()\n",
        "\n",
        "      epoch_loss += loss\n",
        "      epoch_acc += acc\n",
        "\n",
        "  #avg epoch_loss and avg epoch_acc\n",
        "  avg_epoch_loss = epoch_loss/len(val_dataset)\n",
        "  avg_epoch_acc = epoch_acc/len(val_dataset)\n",
        "  return avg_epoch_loss, avg_epoch_acc\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srv-IdctJnj4",
        "outputId": "fd3c13f1-36f0-4c9b-cec7-968dd6722619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        }
      },
      "source": [
        "# real training and evaluation process\n",
        "for epoch in range(epochs):\n",
        "  train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate(model, val_loader, criterion)\n",
        "  print(f'Epoch: {epoch+1:02}')\n",
        "  print(f'\\tTrain Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}')\n",
        "  print(f'\\t Val. Loss: {valid_loss:.4f} | Val. Acc: {valid_acc:.4f}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01\n",
            "\tTrain Loss: 0.0544 | Train Acc: 0.5991\n",
            "\t Val. Loss: 0.0477 | Val. Acc: 0.6175\n",
            "Epoch: 02\n",
            "\tTrain Loss: 0.0409 | Train Acc: 0.6660\n",
            "\t Val. Loss: 0.0366 | Val. Acc: 0.7175\n",
            "Epoch: 03\n",
            "\tTrain Loss: 0.0303 | Train Acc: 0.8118\n",
            "\t Val. Loss: 0.0298 | Val. Acc: 0.7925\n",
            "Epoch: 04\n",
            "\tTrain Loss: 0.0244 | Train Acc: 0.8524\n",
            "\t Val. Loss: 0.0260 | Val. Acc: 0.8275\n",
            "Epoch: 05\n",
            "\tTrain Loss: 0.0205 | Train Acc: 0.8774\n",
            "\t Val. Loss: 0.0277 | Val. Acc: 0.8175\n",
            "Epoch: 06\n",
            "\tTrain Loss: 0.0172 | Train Acc: 0.8874\n",
            "\t Val. Loss: 0.0245 | Val. Acc: 0.8450\n",
            "Epoch: 07\n",
            "\tTrain Loss: 0.0144 | Train Acc: 0.9081\n",
            "\t Val. Loss: 0.0229 | Val. Acc: 0.8650\n",
            "Epoch: 08\n",
            "\tTrain Loss: 0.0119 | Train Acc: 0.9412\n",
            "\t Val. Loss: 0.0212 | Val. Acc: 0.8775\n",
            "Epoch: 09\n",
            "\tTrain Loss: 0.0096 | Train Acc: 0.9581\n",
            "\t Val. Loss: 0.0211 | Val. Acc: 0.8925\n",
            "Epoch: 10\n",
            "\tTrain Loss: 0.0082 | Train Acc: 0.9656\n",
            "\t Val. Loss: 0.0228 | Val. Acc: 0.8975\n",
            "Epoch: 11\n",
            "\tTrain Loss: 0.0073 | Train Acc: 0.9737\n",
            "\t Val. Loss: 0.0209 | Val. Acc: 0.9100\n",
            "Epoch: 12\n",
            "\tTrain Loss: 0.0058 | Train Acc: 0.9819\n",
            "\t Val. Loss: 0.0246 | Val. Acc: 0.9100\n",
            "Epoch: 13\n",
            "\tTrain Loss: 0.0053 | Train Acc: 0.9812\n",
            "\t Val. Loss: 0.0237 | Val. Acc: 0.9175\n",
            "Epoch: 14\n",
            "\tTrain Loss: 0.0047 | Train Acc: 0.9819\n",
            "\t Val. Loss: 0.0245 | Val. Acc: 0.9175\n",
            "Epoch: 15\n",
            "\tTrain Loss: 0.0043 | Train Acc: 0.9850\n",
            "\t Val. Loss: 0.0240 | Val. Acc: 0.9200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUId8TiIW-rC"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}