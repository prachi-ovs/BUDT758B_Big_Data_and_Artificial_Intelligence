# -*- coding: utf-8 -*-
"""Prachi_Singh.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NmPQx_ZuRz9zcjGrEUOwAM7af03CMuDi
"""

from google.colab import files, drive

drive.mount('/content/drive')

# create/define a CNN model for Handwritten digit recognition problem

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') #specify device either CPU or GPU based on GPU's availability

class MyNet(nn.Module):

#network model
  def __init__(self):   #initialization function
    super().__init__()
    self.conv1 = nn.Conv2d(1,6, 5) # input_channel: 1, number of filters / output_channel:6, kernel size: 5 x 5
    self.pool = nn.MaxPool2d(2,2)  # Maximum pooling of size 2 x 2
    self.conv2 = nn.Conv2d(6,16,5) # input_channel after previous conv2d layer is 6, number of filters: 16, kernel size: 5 x 5
    self.fc1 = nn.Linear(16*4*4, 120)  # 256 is the size of the input vector after flattening
    self.fc2 = nn.Linear(120, 84)    
    self.fc3 = nn.Linear(84,10)   # 10 outputs for digit recognition   

#forward method
  def forward(self,x):
    x = self.pool(F.relu(self.conv1(x)))
    x = self.pool(F.relu(self.conv2(x)))
    x = x.view(-1, self.num_flat_features(x)) # input to the fully connected feedforward network is a vector, using view instead of resize here
    x = F.relu(self.fc1(x))
    x = F.relu(self.fc2(x))
    x = F.log_softmax(self.fc3(x))

    return x

  def num_flat_features(self, x):
    size = x.size()[1:] # ignoring the batch size
    num_features = 1
    for s in size:
      num_features *= s  # channel size x width x height gives the flattened vector value
    
    return num_features


net = MyNet().to(device)  # place the instance on the gpu
print(net)

# Creating a customized dataset

# Torch provides a dataset class and we want to inherit it, by creating a sub-class
# This will help create a customized dataset
# Within the dataset there are many instances, each instance may contain different type of properties/features based on the design. 
# For us, each instance is the image as a np array along with a label
import os
import glob
import numpy as np  
from skimage import io # skimage converts images into a numpy array
from torch.utils.data import Dataset, DataLoader

class MNISTDataset(Dataset):  # creating the subclass of the Dataset class provided by Torch, which will be our customized dataset

  # now we need to over ride __init()__, __len()__, and __getitem()__ methods
  def __init__(self, dir, transform = None):
    self.dir = dir
    self.transform = transform  # these transforms are the transform functions such as Rescale and ToTensor

  def __len__(self):
    files = glob.glob(self.dir+'/*.jpg')[:500]  # 100 instances per digit type 
    return len(files)
  
  def __getitem__(self, idx):  
    if torch.is_tensor(idx): # convert index from tensor to list
      dx = idx.tolist()
    
    all_instances = glob.glob(self.dir+'/*.jpg')[:500] # returns a list of file names
    img_fname = os.path.join(self.dir, all_instances[idx])  # obtain a obsolute path to that file with index idx
    image = io.imread(img_fname) # return numpy array of image
    digit = int(self.dir.split('/')[-1].strip())   # last item of list after splitting the file name is the digit
    label = np.array(digit) # convert int to array

    instance = {'image':image, 'label':label}  # each instance in a batch is a dictionary now with values being numpy arrays
    if self.transform:
      instance = self.transform(instance)

    return instance

# Create a customized transformation for each instance in the dataset

# the size of all images in a dataset is not necessarily the same, which is why this action needs to be performed
from skimage import transform
from torchvision import transforms, utils

class Rescale(object):
  # need to override __init__() and __call__() methods

  def __init__(self, output_size): # output_size is the size that all images should have. This can either be an integer value or a tuple (width, height)
    assert isinstance(output_size, (int, tuple)) # checks if output_size is int or tuple
    self.output_size = output_size

  def __call__(self, sample): 
    image, label = sample['image'], sample['label']  # image and label are numpy arrays

    h,w = image.shape[-2:]  # 1st dimension can be the channel hence ignoring it. Only last 2 dimensions needed
    if isinstance(self.output_size, int):  
      if h > w: # rows greater than columns
        new_h, new_w = self.output_size*h/w , self.output_size
      else:
        new_h, new_w = self.output_size , self.output_size*w/h
    else:  # output_Size is a tuple
      new_h, new_w = self.output_size

    new_h, new_w = int(new_h), int(new_w)  # these dimensions should be integers

    new_image = transform.resize(image, (new_h, new_w))  #new_image has to have the new size

    return {'image':new_image, 'label':label}  # all instances now have a new size 


class ToTensor(object): # converting each instance to a tensor
  def __call__(self, sample):
    image, label = sample['image'], sample['label']  # need to convert these numpy arrays to tensors
    image = image.reshape((1,image.shape[0],image.shape[1]))  # to add the channel to each image, 3-d array expected by the convolution layer
    return {'image':torch.from_numpy(image) ,'label': torch.from_numpy(label)} # converting each numpy arrays into tensor

# Create Training and Validation Dataloader 

# to get a batch from the dataset after every iteration
# Read 100 images from each folder --> 10 folders --> add all data sets into one list --> combine all list items into on dataset --> each instance in the dataset is a dictionary --> 2 key value pairs --> image: tensor (1 x 28 x 28) , label: tensor (1 x 1)
from torch.utils.data import random_split

batch_size = 32
list_datasets = []
for i in range(10):  # since there are 10 different subfolders
  # for every iteration one dataset is created
  cur_ds = MNISTDataset('/content/drive/My Drive/Masters/Homework/Big Data and AI/Lab2/trainingset/'+str(i), transform = transforms.Compose([Rescale(28),ToTensor()])) # Compose used since more than one transformation is being applied 
  list_datasets.append(cur_ds)  # list of datasets for every digit

dataset = torch.utils.data.ConcatDataset(list_datasets) # using Torch function which will return only one dataset with all instances from every dataset in the list_datasets list
print(len(dataset))

train_size = int(len(dataset)*0.7)
val_size = len(dataset) - train_size

# creating the training and validation dataset
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

# creating the training and validation dataloader
train_dataloader = DataLoader(train_dataset, batch_size= batch_size, shuffle= True,num_workers= 1)
val_dataloader = DataLoader(val_dataset, batch_size= batch_size, shuffle= True,num_workers= 1)

# Training
epochs = 5
learning_rate = 1e-3
optimizer = optim.Adam(net.parameters(), lr= learning_rate, weight_decay= 1e-5)
criterion = nn.CrossEntropyLoss()

for epoch in range(epochs):

  net.train()  # parameters updated in this mode
  running_loss = 0.0
  for batch_idx, batch in enumerate(train_dataloader):
    inputs, targets = batch['image'].to(device, dtype= torch.float), batch['label'].to(device, dtype= torch.long)

    optimizer.zero_grad()
    predicted_outputs = net(inputs)
    loss = criterion(predicted_outputs, targets)
    loss.backward()
    optimizer.step()

    running_loss += loss.item() # this is to accumulate the loss for each batch
    if (batch_idx+1)%10 == 0: # for every 10 batches in an epoch print the average loss
      print('Epoch: %d, batch: %d, training_loss: %.3f' %(epoch+1, batch_idx+1, running_loss/10))
      running_loss = 0.0 # reset running loss after every 10 batches

  # Validation
  net.eval()

  correct = [0.0]*10 # to check how many instances got correctly classified per digit type
  total = [0.0]*10 # total instances per digit in the validation dataset

  with torch.no_grad(): # to speicify no parameter upgrading during validation
    for batch_idx, batch in enumerate(val_dataloader):
      images, labels = batch['image'].to(device, dtype= torch.float), batch['label'].to(device, dtype= torch.long)
      predicted_outputs = net(images)

      _, predicted_labels = torch.max(predicted_outputs,1)  # 1 indicates column wise, predicted_outputs is batch_Size x 10, so we need to get the indiex of the max predicted value for each image
      c = (predicted_labels == labels)

      for i in range(len(labels)):
        label = labels[i]
        correct[label] += c[i].item()
        total[label] += 1
    
  for i in range(10):
    print('\t Validation Accuracy for digit %d: %.2f' %(i, 100*correct[i]/total[i]))

